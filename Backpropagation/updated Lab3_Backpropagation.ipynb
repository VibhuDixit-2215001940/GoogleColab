{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDYiLpcNjYAf"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# there are some inbuild datasets which are loaded in the sklearn library. In this we are using iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "# We are importing below library for train test split to categorize training data & testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Below is the list of datasets which are available in the sklearn.dataset libray module**\n",
        "## 1. Iris (load_iris)\n",
        "## 2. Digits (load_digits)\n",
        "## 3. Wine (load_wine)\n",
        "## 4. Breast Cancer (load_breast_cancer)\n",
        "## 5. Boston Housing (load_boston) (deprecated)\n",
        "## 6. Diabetes (load_diabetes)\n",
        "## 7. Linnerud (load_linnerud)\n",
        "## 8. California Housing(fetch_california_housing)\n",
        "## 9. 20 Newsgroups (fetch_20newsgroups)\n",
        "## 10. Olivetti Faces (fetch_olivetti_faces)\n",
        "## 11. RCV1 (fetch_rcv1)\n",
        "## 12. Covtype (fetch_covtype)\n",
        "## 13. Kddcup99 (fetch_kddcup99)\n",
        "## 14. Mldata (fetch_mldata) (deprecated)\n",
        "## 15. LFW People (fetch_lfw_people)\n",
        "## 16. LFW Pairs (fetch_lfw_pairs)\n",
        "## 17. OpenML (fetch_openml)a"
      ],
      "metadata": {
        "id": "kuYKSXvkog45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Get features and target\n",
        "X=data.data\n",
        "y=data.target"
      ],
      "metadata": {
        "id": "NO0g_opXjhmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.target_names)"
      ],
      "metadata": {
        "id": "blXgSpdE0C8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.target)"
      ],
      "metadata": {
        "id": "NffZ0zCU02S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.feature_names)"
      ],
      "metadata": {
        "id": "92l-DdPi0vO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.data)"
      ],
      "metadata": {
        "id": "6Lfcac8O065n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'y' is ACTUALLY a 1D array of labels, and you want to one-hot encode it\n",
        "y_dummies = pd.get_dummies(y).values\n",
        "\n",
        "print(y_dummies[:3])"
      ],
      "metadata": {
        "id": "mBLeTUYUjmd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=4)"
      ],
      "metadata": {
        "id": "PS_Syb-VjwPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "learning_rate = 0.1 #It is a hyperparameter that controls the step size during weight updates in training a neural network.\n",
        "# Large learning Rate= 0.1\n",
        "# Moderate Learning Rate: 0.01\n",
        "# Small Learning rate: 0.001\n",
        "# Very Small Learning Rate: 0.0001\n",
        "# Very Very Small Learning Rate: 0.00001\n",
        "# Very Very Very Small Learning Rate: 0.000001 upto ...\n",
        "iterations = 5000\n",
        "N = y_train.size\n",
        "\n",
        "# number of input features\n",
        "input_size = 4\n",
        "\n",
        "# number of hidden layers neurons\n",
        "hidden_size = 2\n",
        "\n",
        "# number of neurons at the output layer\n",
        "output_size = 3\n",
        "\n",
        "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
      ],
      "metadata": {
        "id": "khRTMxn4j5IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "np.random.seed(10)\n",
        "\n",
        "# initializing weight for the hidden layer\n",
        "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))\n",
        "\n",
        "# initializing weight for the output layer\n",
        "W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size))"
      ],
      "metadata": {
        "id": "-nctmlapkl_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(y_pred, y_true):\n",
        "    # Convert y_true to a 2D array if it's 1D\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true[:, np.newaxis]\n",
        "    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    # Convert y_true to a 2D array if it's 1D\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true[:, np.newaxis]\n",
        "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
        "    return acc.mean()"
      ],
      "metadata": {
        "id": "PzD-7IIElDXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a list to collect results\n",
        "results = []"
      ],
      "metadata": {
        "id": "eNrAMQqJmqxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(iterations):\n",
        "    # Feedforward propagation\n",
        "    Z1 = np.dot(X_train, W1)\n",
        "    A1 = sigmoid(Z1)\n",
        "\n",
        "    # On output layer\n",
        "    Z2 = np.dot(A1, W2)\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    # Calculating error\n",
        "    mse = mean_squared_error(A2, y_train)\n",
        "    acc = accuracy(A2, y_train)\n",
        "    results.append({\"mse\": mse, \"accuracy\": acc})\n",
        "\n",
        "    # Backpropagation\n",
        "    # Reshape y_train to be a 2D array for compatibility with A2\n",
        "    y_train_reshaped = y_train.reshape(-1, 1)\n",
        "    E1 = A2 - y_train_reshaped  # Now the subtraction should work\n",
        "    dW1 = E1 * A2 * (1 - A2)\n",
        "\n",
        "    E2 = np.dot(dW1, W2.T)\n",
        "    dW2 = E2 * A1 * (1 - A1)\n",
        "\n",
        "    # Weight updates\n",
        "    W2_update = np.dot(A1.T, dW1) / N\n",
        "    W1_update = np.dot(X_train.T, dW2) / N\n",
        "\n",
        "    W2 = W2 - learning_rate * W2_update\n",
        "    W1 = W1 - learning_rate * W1_update"
      ],
      "metadata": {
        "id": "5SQslzDDlIsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "reAGTmvemxzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.mse.plot(title=\"Mean Squared Error\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zq1zkQ6cmGKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.accuracy.plot(title=\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4IibV0ymG5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feedforward\n",
        "Z1 = np.dot(X_test, W1)\n",
        "A1 = sigmoid(Z1)\n",
        "\n",
        "Z2 = np.dot(A1, W2)\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "acc = accuracy(A2, y_test)\n",
        "print(\"Accuracy: {}\".format(acc))"
      ],
      "metadata": {
        "id": "bGvbffDxmKNd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}